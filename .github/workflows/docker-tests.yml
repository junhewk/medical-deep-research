name: Docker Tests (Consolidated)

on:
  pull_request:
    types: [opened, synchronize, reopened]
    branches: [ main, dev ]
  push:
    branches: [ main ]
  workflow_dispatch:

# Top-level permissions set to minimum (OSSF Scorecard Token-Permissions)
permissions: {}

env:
  TEST_IMAGE: ldr-test
  PAGES_URL: https://learningcircuit.github.io/local-deep-research/

jobs:
  # Detect which paths changed to conditionally run certain jobs
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      llm: ${{ steps.filter.outputs.llm }}
      infrastructure: ${{ steps.filter.outputs.infrastructure }}
    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@e3f713f2d8f53843e71c69a996d56f51aa9adfb9 # v2.14.1
        with:
          egress-policy: audit

      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          persist-credentials: false

      - uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3.0.2
        id: filter
        with:
          filters: |
            llm:
              - 'src/local_deep_research/llm/**'
              - 'src/local_deep_research/config/llm_config.py'
              - 'src/local_deep_research/api/research_functions.py'
              - 'tests/test_llm/**'
              - '.github/workflows/docker-tests.yml'
            infrastructure:
              - 'src/local_deep_research/web/routes/**'
              - 'src/local_deep_research/web/static/js/**'
              - 'tests/infrastructure_tests/**'
              - '.github/workflows/docker-tests.yml'

  # Build Docker image once and share via artifact
  build-test-image:
    runs-on: ubuntu-latest
    name: Build Test Image
    if: |
      github.event_name == 'pull_request' ||
      github.ref == 'refs/heads/main' ||
      github.ref == 'refs/heads/dev'

    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@e3f713f2d8f53843e71c69a996d56f51aa9adfb9 # v2.14.1
        with:
          egress-policy: audit

      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          persist-credentials: false

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@8d2750c68a42422c14e847fe6c8ac0403b4cbd6f # v3

      - name: Build Docker image with cache
        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83 # v6
        with:
          context: .
          target: ldr-test
          outputs: type=docker,dest=/tmp/ldr-test.tar
          tags: ${{ env.TEST_IMAGE }}
          # Cache poisoning protection: only read/write cache on trusted events (not PRs from forks)
          cache-from: ${{ github.event_name != 'pull_request' && 'type=gha,scope=ldr-test' || '' }}
          cache-to: ${{ github.event_name != 'pull_request' && 'type=gha,mode=max,scope=ldr-test' || '' }}

      - name: Upload Docker image as artifact
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: docker-image
          path: /tmp/ldr-test.tar
          retention-days: 1

  # Run all pytest tests with coverage
  pytest-tests:
    runs-on: ubuntu-latest
    name: All Pytest Tests + Coverage
    needs: build-test-image
    permissions:
      contents: write      # Needed for gh-pages deployment
      pull-requests: write # Needed for PR comments

    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@e3f713f2d8f53843e71c69a996d56f51aa9adfb9 # v2.14.1
        with:
          egress-policy: audit

      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          persist-credentials: true  # Needed for gh-pages push

      - name: Download Docker image
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: docker-image
          path: /tmp

      - name: Load Docker image
        run: docker load --input /tmp/ldr-test.tar

      - name: Set up Node.js
        # zizmor: ignore[cache-poisoning] - caching explicitly disabled with cache: ''
        uses: actions/setup-node@6044e13b5dc448c55e2357c09f80417699197238 # v6.2.0
        with:
          node-version: '20'
          # Cache poisoning protection: explicitly disable caching on PR events from forks
          cache: ''

      - name: Install infrastructure test dependencies
        run: |
          cd tests/infrastructure_tests && npm ci

      - name: Run all pytest tests with coverage
        # Continue even if some tests fail - we still want the coverage report
        continue-on-error: true
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        run: |
          mkdir -p coverage
          docker run --rm \
            -v "$PWD":/app \
            -e CI=true \
            -e GITHUB_ACTIONS=true \
            -e LDR_USE_FALLBACK_LLM=true \
            -e LDR_TESTING_WITH_MOCKS=true \
            -e DISABLE_RATE_LIMITING=true \
            -e PYTHONPATH=/app/src \
            -e OPENROUTER_API_KEY="${OPENROUTER_API_KEY}" \
            -w /app \
            ${{ env.TEST_IMAGE }} \
            sh -c "python -m pytest tests/ \
              --cov=src \
              --cov-report=term-missing \
              --cov-report=xml:coverage/coverage.xml \
              --cov-report=html:coverage/htmlcov \
              -v --tb=short \
              --durations=20 \
              -n auto \
              --ignore=tests/ui_tests \
              --ignore=tests/infrastructure_tests \
              --ignore=tests/fuzz"

      - name: Run JavaScript infrastructure tests
        run: |
          cd tests/infrastructure_tests && npm test

      - name: Generate coverage summary
        if: always()
        run: |
          {
            echo "## Coverage Report"
            echo ""
            if [ -f coverage/coverage.xml ]; then
              # Extract total coverage from XML
              COVERAGE=$(python3 -c "import xml.etree.ElementTree as ET; tree = ET.parse('coverage/coverage.xml'); print(f\"{float(tree.getroot().get('line-rate', 0)) * 100:.1f}%\")" 2>/dev/null || echo "N/A")
              echo "**Total Line Coverage: ${COVERAGE}**"
              echo ""
              echo "ðŸ“Š **[View Full Coverage Report](${{ env.PAGES_URL }})** - Interactive HTML report with line-by-line details"
              echo ""
              echo "_Note: Report updates after merge to main/dev branch._"
            else
              echo "âš ï¸ Coverage report not generated"
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload coverage reports
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: coverage-report
          path: coverage/

      # Fix permissions on coverage directory (Docker creates files as root)
      - name: Fix coverage directory permissions
        if: always()
        run: |
          if [ -d "coverage" ]; then
            sudo chown -R "$(id -u):$(id -g)" coverage/
            echo "Coverage directory owner after chown:"
            stat coverage/
            if [ -d "coverage/htmlcov" ]; then
              echo "HTML coverage file count:"
              find coverage/htmlcov/ -type f | wc -l
              echo "Sample files:"
              find coverage/htmlcov/ -maxdepth 1 -type f -name "*.html" | head -5
            else
              echo "ERROR: coverage/htmlcov directory does not exist!"
            fi
          else
            echo "ERROR: coverage directory does not exist!"
          fi

      # Deploy coverage HTML report to GitHub Pages
      # Only deploys on main/dev branch pushes (not PRs)
      # Note: continue-on-error prevents deployment failures from failing the tests badge
      - name: Deploy coverage to GitHub Pages
        continue-on-error: true
        if: |
          always() &&
          github.ref == 'refs/heads/main' &&
          github.event_name == 'push'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -ex

          # Check source exists
          if [ ! -d "coverage/htmlcov" ]; then
            echo "ERROR: coverage/htmlcov does not exist"
            exit 1
          fi

          FILE_COUNT=$(find coverage/htmlcov -type f | wc -l)
          echo "Found $FILE_COUNT files to deploy"

          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "ERROR: No files to deploy"
            exit 1
          fi

          # Copy to a fresh directory to avoid Docker volume/git issues
          DEPLOY_DIR=$(mktemp -d)
          cp -r coverage/htmlcov/* "$DEPLOY_DIR/"
          cd "$DEPLOY_DIR"

          # Create .nojekyll to bypass Jekyll processing
          touch .nojekyll

          # Debug: show what we have
          echo "Files in deploy dir:"
          find . -type f | head -10
          echo "Total files: $(find . -type f | wc -l)"

          # Setup git
          git init
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Add all files and commit
          git add -A
          git status
          git commit -m "docs: update coverage report ${{ github.sha }}"

          # Force push to gh-pages branch
          git push --force "https://x-access-token:${GITHUB_TOKEN}@github.com/${{ github.repository }}.git" HEAD:gh-pages

          echo "Deployment complete!"
          rm -rf "$DEPLOY_DIR"

      # Add coverage summary as PR comment for easy visibility
      - name: Comment coverage on PR
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            const fs = require('fs');

            let lineCoverage = 'N/A';
            let branchCoverage = 'N/A';
            let linesCovered = 0;
            let linesTotal = 0;
            let filesAnalyzed = 0;
            let lowestCoverageFiles = [];

            try {
              if (fs.existsSync('coverage/coverage.xml')) {
                const xml = fs.readFileSync('coverage/coverage.xml', 'utf8');

                // Extract overall metrics
                const lineMatch = xml.match(/line-rate="([^"]+)"/);
                const branchMatch = xml.match(/branch-rate="([^"]+)"/);
                const coveredMatch = xml.match(/lines-covered="([^"]+)"/);
                const validMatch = xml.match(/lines-valid="([^"]+)"/);

                if (lineMatch) lineCoverage = (parseFloat(lineMatch[1]) * 100).toFixed(1) + '%';
                if (branchMatch) branchCoverage = (parseFloat(branchMatch[1]) * 100).toFixed(1) + '%';
                if (coveredMatch) linesCovered = parseInt(coveredMatch[1]);
                if (validMatch) linesTotal = parseInt(validMatch[1]);

                // Extract per-file coverage to find lowest coverage files
                const classMatches = xml.matchAll(/<class[^>]+filename="([^"]+)"[^>]+line-rate="([^"]+)"/g);
                const fileCoverages = [];
                for (const match of classMatches) {
                  const filename = match[1].replace(/^src\//, '').replace(/^local_deep_research\//, '');
                  const rate = parseFloat(match[2]) * 100;
                  fileCoverages.push({ filename, rate });
                  filesAnalyzed++;
                }

                // Sort by coverage (lowest first) and get bottom 5 with <50% coverage
                lowestCoverageFiles = fileCoverages
                  .filter(f => f.rate < 50)
                  .sort((a, b) => a.rate - b.rate)
                  .slice(0, 5);
              }
            } catch (e) {
              console.log('Could not parse coverage:', e);
            }

            // Build the lowest coverage files section
            let lowestFilesSection = '';
            if (lowestCoverageFiles.length > 0) {
              lowestFilesSection = '\n**Files needing attention** (<50% coverage):\n' +
                lowestCoverageFiles.map(f => `- \`${f.filename}\`: ${f.rate.toFixed(1)}%`).join('\n');
            }

            const body = `## ðŸ“Š Coverage Report

            | Metric | Value |
            |--------|-------|
            | **Line Coverage** | ${lineCoverage} |
            | **Branch Coverage** | ${branchCoverage} |
            | **Lines** | ${linesCovered.toLocaleString()} / ${linesTotal.toLocaleString()} |
            | **Files Analyzed** | ${filesAnalyzed} |

            ðŸ“ˆ [View Full Report](${{ env.PAGES_URL }}) _(updates after merge)_

            <details>
            <summary>ðŸ“‰ Coverage Details</summary>
            ${lowestFilesSection || '\nâœ… All files have >50% coverage!'}

            ---
            - Coverage is calculated from \`src/\` directory
            - Full interactive HTML report available after merge to main/dev
            - Download artifacts for immediate detailed view

            </details>`;

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(c =>
              c.user.type === 'Bot' && c.body.includes('ðŸ“Š Coverage Report')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }

      # Coverage badge via GitHub Gist + shields.io (no third-party service needed)
      # How it works:
      # 1. We store a JSON file in a GitHub Gist (gist.github.com - GitHub's snippet/paste service)
      # 2. shields.io reads that JSON to generate a badge image
      # 3. README references the shields.io URL to display the badge
      # Setup: Create a gist, add GIST_TOKEN (PAT with gist scope) and COVERAGE_GIST_ID secrets
      - name: Update coverage badge
        if: github.ref == 'refs/heads/dev' && github.event_name == 'push'
        env:
          GIST_TOKEN: ${{ secrets.GIST_TOKEN }}
        run: |
          if [ -z "$GIST_TOKEN" ]; then
            echo "GIST_TOKEN not set, skipping badge update"
            exit 0
          fi
          if [ -f coverage/coverage.xml ]; then
            COVERAGE=$(python3 -c "import xml.etree.ElementTree as ET; tree = ET.parse('coverage/coverage.xml'); print(f\"{float(tree.getroot().get('line-rate', 0)) * 100:.0f}\")" 2>/dev/null || echo "0")
            # Determine color based on coverage
            if [ "$COVERAGE" -ge 80 ]; then
              COLOR="brightgreen"
            elif [ "$COVERAGE" -ge 60 ]; then
              COLOR="green"
            elif [ "$COVERAGE" -ge 40 ]; then
              COLOR="yellow"
            else
              COLOR="red"
            fi
            # Create badge JSON
            echo "{\"schemaVersion\":1,\"label\":\"coverage\",\"message\":\"${COVERAGE}%\",\"color\":\"${COLOR}\"}" > coverage-badge.json
            # Update gist (requires GIST_TOKEN secret and GIST_ID)
            if [ -n "${{ secrets.COVERAGE_GIST_ID }}" ]; then
              curl -s -X PATCH \
                -H "Authorization: token ${GIST_TOKEN}" \
                -H "Accept: application/vnd.github.v3+json" \
                "https://api.github.com/gists/${{ secrets.COVERAGE_GIST_ID }}" \
                -d "{\"files\":{\"coverage-badge.json\":{\"content\":$(jq -Rs . < coverage-badge.json)}}}"
            fi
          fi

  # Run UI tests with Puppeteer
  ui-tests:
    runs-on: ubuntu-latest
    name: UI Tests (Puppeteer)
    needs: build-test-image
    permissions:
      contents: read

    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@e3f713f2d8f53843e71c69a996d56f51aa9adfb9 # v2.14.1
        with:
          egress-policy: audit

      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          persist-credentials: false

      - name: Download Docker image
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: docker-image
          path: /tmp

      - name: Load Docker image
        run: docker load --input /tmp/ldr-test.tar

      - name: Install Node.js for UI tests
        # zizmor: ignore[cache-poisoning] - caching explicitly disabled with cache: ''
        uses: actions/setup-node@6044e13b5dc448c55e2357c09f80417699197238 # v6.2.0
        with:
          node-version: '20'
          # Cache poisoning protection: explicitly disable caching on PR events from forks
          cache: ''

      - name: Install UI test dependencies
        run: |
          export PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true
          cd tests && npm ci

      - name: Start application server in Docker
        run: |
          docker run -d \
            --name ldr-server \
            -p 5000:5000 \
            -e CI=true \
            -e TEST_ENV=true \
            -e FLASK_ENV=testing \
            -e LDR_USE_FALLBACK_LLM=true \
            -e DISABLE_RATE_LIMITING=true \
            -e SECRET_KEY=test-secret-key-for-ci \
            ${{ env.TEST_IMAGE }} ldr-web

          # Wait for server to be ready
          for i in {1..60}; do
            if curl -f http://localhost:5000/api/v1/health 2>/dev/null; then
              echo "Server is ready after $i seconds"
              break
            fi
            if ! docker ps --filter "name=ldr-server" --filter "status=running" -q | grep -q .; then
              echo "Server container died!"
              echo "Server log:"
              docker logs ldr-server
              exit 1
            fi
            echo "Waiting for server... ($i/60)"
            sleep 1
          done

          # Final check
          if ! curl -f http://localhost:5000/api/v1/health 2>/dev/null; then
            echo "Server failed to start after 60 seconds"
            echo "Server log:"
            docker logs ldr-server
            exit 1
          fi

      - name: Register CI test user
        run: |
          docker run --rm \
            -v "$PWD":/app \
            -e CI=true \
            --network host \
            -w /app/tests/ui_tests \
            ${{ env.TEST_IMAGE }} \
            node register_ci_user.js http://localhost:5000

      - name: Run UI tests
        run: |
          docker run --rm \
            -v "$PWD":/app \
            -e LDR_USE_FALLBACK_LLM=true \
            -e LDR_TESTING_WITH_MOCKS=true \
            -e CI=true \
            -e PUPPETEER_HEADLESS=true \
            --network host \
            -w /app/tests/ui_tests \
            ${{ env.TEST_IMAGE }} \
            sh -c "xvfb-run -a -s '-screen 0 1920x1080x24' node run_all_tests.js || node run_all_tests.js"

      - name: Stop server
        if: always()
        run: |
          docker stop ldr-server || true
          docker rm ldr-server || true

      - name: Upload UI test screenshots
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: ui-test-screenshots
          path: |
            tests/screenshots/
            tests/ui_tests/screenshots/

  # Run LLM unit tests (conditional on path changes)
  llm-unit-tests:
    runs-on: ubuntu-latest
    name: LLM Unit Tests
    needs: [build-test-image, detect-changes]
    if: needs.detect-changes.outputs.llm == 'true' || github.event_name == 'workflow_dispatch'
    permissions:
      contents: read

    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@e3f713f2d8f53843e71c69a996d56f51aa9adfb9 # v2.14.1
        with:
          egress-policy: audit

      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          persist-credentials: false

      - name: Download Docker image
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: docker-image
          path: /tmp

      - name: Load Docker image
        run: docker load --input /tmp/ldr-test.tar

      - name: Run LLM registry tests
        run: |
          docker run --rm \
            -v "$PWD":/app \
            -e PYTHONPATH=/app \
            -w /app \
            ${{ env.TEST_IMAGE }} \
            sh -c "python -m pytest tests/test_llm/test_llm_registry.py -v -n auto"

      - name: Run LLM integration tests
        run: |
          docker run --rm \
            -v "$PWD":/app \
            -e PYTHONPATH=/app \
            -e LDR_USE_FALLBACK_LLM=true \
            -w /app \
            ${{ env.TEST_IMAGE }} \
            sh -c "python -m pytest tests/test_llm/test_llm_integration.py -v -n auto"

      - name: Run API LLM integration tests
        run: |
          docker run --rm \
            -v "$PWD":/app \
            -e PYTHONPATH=/app \
            -e LDR_USE_FALLBACK_LLM=true \
            -w /app \
            ${{ env.TEST_IMAGE }} \
            sh -c "python -m pytest tests/test_llm/test_api_llm_integration.py -v -n auto"

      - name: Run LLM edge case tests
        run: |
          docker run --rm \
            -v "$PWD":/app \
            -e PYTHONPATH=/app \
            -w /app \
            ${{ env.TEST_IMAGE }} \
            sh -c "python -m pytest tests/test_llm/test_llm_edge_cases.py -v -n auto"

      - name: Run LLM benchmark tests
        run: |
          docker run --rm \
            -v "$PWD":/app \
            -e PYTHONPATH=/app \
            -w /app \
            ${{ env.TEST_IMAGE }} \
            sh -c "python -m pytest tests/test_llm/test_llm_benchmarks.py -v -n auto"

  # Run LLM example tests (conditional on path changes)
  llm-example-tests:
    runs-on: ubuntu-latest
    name: LLM Example Tests
    needs: [build-test-image, detect-changes]
    if: needs.detect-changes.outputs.llm == 'true' || github.event_name == 'workflow_dispatch'
    permissions:
      contents: read

    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@e3f713f2d8f53843e71c69a996d56f51aa9adfb9 # v2.14.1
        with:
          egress-policy: audit

      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          persist-credentials: false

      - name: Download Docker image
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: docker-image
          path: /tmp

      - name: Load Docker image
        run: docker load --input /tmp/ldr-test.tar

      - name: Test basic custom LLM example
        run: |
          docker run --rm \
            -v "$PWD":/app \
            -e PYTHONPATH=/app \
            -e LDR_USE_FALLBACK_LLM=true \
            -w /app \
            ${{ env.TEST_IMAGE }} \
            sh -c "timeout 60s python examples/llm_integration/basic_custom_llm.py || true"

      - name: Test mock LLM example
        run: |
          docker run --rm \
            -v "$PWD":/app \
            -e PYTHONPATH=/app \
            -e LDR_USE_FALLBACK_LLM=true \
            -w /app \
            ${{ env.TEST_IMAGE }} \
            sh -c "timeout 60s python examples/llm_integration/mock_llm_example.py || true"

      - name: Test provider switching example
        run: |
          docker run --rm \
            -v "$PWD":/app \
            -e PYTHONPATH=/app \
            -e LDR_USE_FALLBACK_LLM=true \
            -w /app \
            ${{ env.TEST_IMAGE }} \
            sh -c "timeout 60s python examples/llm_integration/switch_providers.py || true"

      - name: Test custom research example
        run: |
          docker run --rm \
            -v "$PWD":/app \
            -e PYTHONPATH=/app \
            -e LDR_USE_FALLBACK_LLM=true \
            -w /app \
            ${{ env.TEST_IMAGE }} \
            sh -c "timeout 60s python examples/llm_integration/custom_research_example.py || true"

  # Run infrastructure tests (conditional on path changes)
  infrastructure-tests:
    runs-on: ubuntu-latest
    name: Infrastructure Tests
    needs: [build-test-image, detect-changes]
    if: needs.detect-changes.outputs.infrastructure == 'true' || github.event_name == 'workflow_dispatch'
    permissions:
      contents: read

    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@e3f713f2d8f53843e71c69a996d56f51aa9adfb9 # v2.14.1
        with:
          egress-policy: audit

      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          persist-credentials: false

      - name: Download Docker image
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: docker-image
          path: /tmp

      - name: Load Docker image
        run: docker load --input /tmp/ldr-test.tar

      - name: Set up Node.js
        uses: actions/setup-node@6044e13b5dc448c55e2357c09f80417699197238 # v6.2.0
        with:
          node-version: '20'

      - name: Install JavaScript test dependencies
        run: |
          cd tests/infrastructure_tests && npm ci

      - name: Run Python infrastructure tests
        run: |
          docker run --rm \
            -v "$PWD":/app \
            -w /app \
            ${{ env.TEST_IMAGE }} \
            sh -c "cd /app && python -m pytest tests/infrastructure_tests/test_*.py -v --color=yes --no-header -rN"

      - name: Run JavaScript infrastructure tests
        run: |
          cd tests/infrastructure_tests && npm test

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: infrastructure-test-results
          path: |
            tests/infrastructure_tests/coverage/
            tests/infrastructure_tests/test-results/
